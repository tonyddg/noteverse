import{_ as i}from"./plugin-vue_export-helper-c27b6911.js";import{r as c,o as l,c as o,b as s,d as n,a as e,e as a}from"./app-8c5ce49e.js";const p="/noteverse/assets/sklearn_decisiontree-ee11c2e6.svg",r="/noteverse/assets/sklearn_kmean-94825831.svg",d="/noteverse/assets/sklearn_paramcurve-db42e12d.svg",u={},m=a('<h1 id="机器学习" tabindex="-1"><a class="header-anchor" href="#机器学习" aria-hidden="true">#</a> 机器学习</h1><h2 id="scikit-learn-模型特点" tabindex="-1"><a class="header-anchor" href="#scikit-learn-模型特点" aria-hidden="true">#</a> Scikit-Learn 模型特点</h2><p>在 Scikit-Learn 模块中, 统一使用模型对象标识不同的模型, 并且模型对象均具有以下两个成员函数用于训练与预测模型</p><p>训练模型 <code>model.fit(X, y, sample_weight = None)</code></p><ul><li><code>X</code> 大小为 <code>(samples, features)</code> 的二维训练样本特征数组, 即每行对应一条样本, 每列对应一个样本特征</li><li><code>y</code> 大小为 <code>(samples)</code> 的一维训练样本属性数组, 一般传入整数, 表示对应训练样本的分类标签或回归属性 (对于多分类或多目标回归模型有大小 <code>(samples, targets)</code>)</li><li><code>sample_weight</code> 大小为 <code>(samples)</code> 的一维数组或 <code>None</code>, 表示对应样本的权重</li><li>重复训练将覆盖之前的训练参数</li></ul><p>模型预测 <code>C = model.predict(X)</code></p><ul><li><code>X</code> 预测样本特征数组, 类似训练特征</li><li><code>C</code> 模型预测得到的分类标签或回归属性数组</li><li>模型仅有在被训练后才能用于预测</li></ul><p>分类概率预测 <code>T = model.predict_proba(X)</code></p><ul><li><code>X</code> 预测样本特征数组, 类似训练特征</li><li><code>T</code> 大小为 <code>(samples, classes)</code> 的数组, 即直接输出模型预测各个分类的概率</li><li>该方法为大部分分类模型如<a href="#%E5%85%B6%E4%BB%96%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B">分类回归</a>, <a href="#%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B">决策树</a>特有的一种预测函数, 用于<a href="#%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0">集成学习</a>的软投票</li><li>对于<a href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E5%88%86%E7%B1%BB%E4%BD%BF%E7%94%A8">支持向量分类</a>等不能直接输出分类概率的模型, 需要启用超参数 <code>probability = True</code> 才能支持此函数</li></ul><h2 id="线性回归模型" tabindex="-1"><a class="header-anchor" href="#线性回归模型" aria-hidden="true">#</a> 线性回归模型</h2>',10),h={href:"https://scikit-learn.org/stable/modules/linear_model.html#regression",target:"_blank",rel:"noopener noreferrer"},_=s("p",null,[n("线性回归模型相关模块 "),s("code",null,"from sklearn import linear_model")],-1),v=s("p",null,"线性回归模型是用于回归 (Regression) 问题的一类模型, 在此类问题中样本的属性为一个连续值",-1),k=s("p",null,"线性回归一般只能解决低维的, 具有明显线性关系的回归问题",-1),g=s("h3",{id:"线性回归模型原理",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#线性回归模型原理","aria-hidden":"true"},"#"),n(" 线性回归模型原理")],-1),y={class:"katex"},b=s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"x"),s("mo",null,"⃗")])]),s("annotation",{encoding:"application/x-tex"},"\\vec{x}")])])],-1),w={class:"katex-html","aria-hidden":"true"},x={class:"base"},f=s("span",{class:"strut",style:{height:"0.714em"}},null,-1),E={class:"mord accent"},B={class:"vlist-t"},A={class:"vlist-r"},M={class:"vlist",style:{height:"0.714em"}},q=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"x")],-1),z={style:{top:"-3em"}},C=s("span",{class:"pstrut",style:{height:"3em"}},null,-1),S={class:"accent-body",style:{left:"-0.2077em"}},K={class:"overlay",style:{height:"0.714em",width:"0.471em"}},X={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},L=s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1),F=[L],D=s("p",null,"线性回归模型中假定样本的特征与属性之间满足以下线性关系",-1),V={class:"katex-block"},R={class:"katex-display"},H={class:"katex"},N=s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"y"),s("mo",null,"="),s("msup",null,[s("mover",{accent:"true"},[s("mi",null,"w"),s("mo",null,"⃗")]),s("mi",null,"T")]),s("mover",{accent:"true"},[s("mi",null,"x"),s("mo",null,"⃗")]),s("mo",null,"+"),s("mi",null,"b")]),s("annotation",{encoding:"application/x-tex"}," y=\\vec{w}^{T}\\vec{x}+b ")])])],-1),T={class:"katex-html","aria-hidden":"true"},Y=a('<span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span>',1),G={class:"base"},P=s("span",{class:"strut",style:{height:"0.9747em","vertical-align":"-0.0833em"}},null,-1),U={class:"mord"},J={class:"mord accent"},j={class:"vlist-t"},I={class:"vlist-r"},O={class:"vlist",style:{height:"0.714em"}},Q=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w")],-1),W={style:{top:"-3em"}},Z=s("span",{class:"pstrut",style:{height:"3em"}},null,-1),$={class:"accent-body",style:{left:"-0.1522em"}},ss={class:"overlay",style:{height:"0.714em",width:"0.471em"}},ns={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},as=s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1),ts=[as],es=a('<span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span>',1),ls={class:"mord accent"},os={class:"vlist-t"},is={class:"vlist-r"},cs={class:"vlist",style:{height:"0.714em"}},ps=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"x")],-1),rs={style:{top:"-3em"}},ds=s("span",{class:"pstrut",style:{height:"3em"}},null,-1),us={class:"accent-body",style:{left:"-0.2077em"}},ms={class:"overlay",style:{height:"0.714em",width:"0.471em"}},hs={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},_s=s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1),vs=[_s],ks=s("span",{class:"mspace",style:{"margin-right":"0.2222em"}},null,-1),gs=s("span",{class:"mbin"},"+",-1),ys=s("span",{class:"mspace",style:{"margin-right":"0.2222em"}},null,-1),bs=s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal"},"b")],-1),ws={class:"katex"},xs=s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"w"),s("mo",null,"⃗")])]),s("annotation",{encoding:"application/x-tex"},"\\vec{w}")])])],-1),fs={class:"katex-html","aria-hidden":"true"},Es={class:"base"},Bs=s("span",{class:"strut",style:{height:"0.714em"}},null,-1),As={class:"mord accent"},Ms={class:"vlist-t"},qs={class:"vlist-r"},zs={class:"vlist",style:{height:"0.714em"}},Cs=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w")],-1),Ss={style:{top:"-3em"}},Ks=s("span",{class:"pstrut",style:{height:"3em"}},null,-1),Xs={class:"accent-body",style:{left:"-0.1522em"}},Ls={class:"overlay",style:{height:"0.714em",width:"0.471em"}},Fs={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},Ds=s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1),Vs=[Ds],Rs=s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"b")]),s("annotation",{encoding:"application/x-tex"},"b")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal"},"b")])])],-1),Hs=a('<h3 id="线性回归模型的基本使用" tabindex="-1"><a class="header-anchor" href="#线性回归模型的基本使用" aria-hidden="true">#</a> 线性回归模型的基本使用</h3><p>创建线性回归模型<br><code>reg = linear_model.LinearRegression(*, fit_intercept = True, positive = False)</code></p><ul><li><code>fit_intercept</code> 是否包含截距项</li><li><code>positive</code> 是否要求模型输出一定为正</li></ul><p>获取模型参数</p><ul><li><code>reg.coef_</code> 获取模型系数矩阵, 为 <code>(features)</code> 的一维数组</li><li><code>reg.intercept_</code> 获取模型截距矩阵, 为浮点数</li></ul><p>如果要将线性回归模型用于拟合非线性的数据, 可使用<a href="#%E6%95%B0%E6%8D%AE%E6%B5%81%E6%B0%B4%E7%BA%BF">数据流水线</a>将输入特征进行相乘组合 (<code>PolynomialFeatures</code>) 得到更多维的特征</p><h3 id="其他线性回归模型" tabindex="-1"><a class="header-anchor" href="#其他线性回归模型" aria-hidden="true">#</a> 其他线性回归模型</h3><p>正则化的线性回归<br> 在正则化线性回归中, 在均方差损失函数的基础上加入了关于权重系数的惩罚函数有</p>',8),Ns={class:"katex-block"},Ts={class:"katex-display"},Ys={class:"katex"},Gs=s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"J"),s("mo",null,"="),s("msup",null,[s("mrow",null,[s("mo",{fence:"true"},"∥"),s("mtable",{rowspacing:"0.16em",columnalign:"center",columnspacing:"1em"},[s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"false"},[s("mrow",null,[s("mo",{stretchy:"false"},"("),s("msup",null,[s("mover",{accent:"true"},[s("mi",null,"w"),s("mo",null,"⃗")]),s("mi",null,"T")]),s("mover",{accent:"true"},[s("mi",null,"x"),s("mo",null,"⃗")]),s("mo",null,"+"),s("mi",null,"b"),s("mo",{stretchy:"false"},")"),s("mo",null,"−"),s("mi",null,"y")])])])])]),s("mo",{fence:"true"},"∥")]),s("mn",null,"2")]),s("mo",null,"+"),s("mi",null,"α"),s("mi",null,"G"),s("mo",{stretchy:"false"},"("),s("mover",{accent:"true"},[s("mi",null,"w"),s("mo",null,"⃗")]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," J=\\begin{Vmatrix}(\\vec{w}^T\\vec{x}+b)-y\\end{Vmatrix}^2+\\alpha G(\\vec{w}) ")])])],-1),Ps={class:"katex-html","aria-hidden":"true"},Us=a('<span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span>',1),Js={class:"base"},js=s("span",{class:"strut",style:{height:"1.4053em","vertical-align":"-0.3507em"}},null,-1),Is={class:"minner"},Os={class:"minner"},Qs=a(`<span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-2.85em;"><span class="pstrut" style="height:3.2em;"></span><span style="width:0.556em;height:1.200em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.556em" height="1.200em" viewBox="0 0 556 1200"><path d="M145 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M188 15 H145 v585 v0 v585 h43z
M367 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M410 15 H367 v585 v0 v585 h43z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span></span>`,1),Ws={class:"mord"},Zs={class:"mtable"},$s={class:"col-align-c"},sn={class:"vlist-t vlist-t2"},nn={class:"vlist-r"},an={class:"vlist",style:{height:"0.8507em"}},tn={style:{top:"-3.0093em"}},en=s("span",{class:"pstrut",style:{height:"3em"}},null,-1),ln={class:"mord"},on=s("span",{class:"mopen"},"(",-1),cn={class:"mord"},pn={class:"mord accent"},rn={class:"vlist-t"},dn={class:"vlist-r"},un={class:"vlist",style:{height:"0.714em"}},mn=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w")],-1),hn={style:{top:"-3em"}},_n=s("span",{class:"pstrut",style:{height:"3em"}},null,-1),vn={class:"accent-body",style:{left:"-0.1522em"}},kn={class:"overlay",style:{height:"0.714em",width:"0.471em"}},gn={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},yn=s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1),bn=[yn],wn=a('<span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span>',1),xn={class:"mord accent"},fn={class:"vlist-t"},En={class:"vlist-r"},Bn={class:"vlist",style:{height:"0.714em"}},An=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"x")],-1),Mn={style:{top:"-3em"}},qn=s("span",{class:"pstrut",style:{height:"3em"}},null,-1),zn={class:"accent-body",style:{left:"-0.2077em"}},Cn={class:"overlay",style:{height:"0.714em",width:"0.471em"}},Sn={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},Kn=s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1),Xn=[Kn],Ln=a('<span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">b</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span>',9),Fn=s("span",{class:"vlist-s"},"​",-1),Dn=s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3507em"}},[s("span")])],-1),Vn=a(`<span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-2.85em;"><span class="pstrut" style="height:3.2em;"></span><span style="width:0.556em;height:1.200em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.556em" height="1.200em" viewBox="0 0 556 1200"><path d="M145 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M188 15 H145 v585 v0 v585 h43z
M367 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M410 15 H367 v585 v0 v585 h43z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span></span>`,1),Rn=a('<span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0547em;"><span style="top:-3.3036em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span>',1),Hn=s("span",{class:"mspace",style:{"margin-right":"0.2222em"}},null,-1),Nn=s("span",{class:"mbin"},"+",-1),Tn=s("span",{class:"mspace",style:{"margin-right":"0.2222em"}},null,-1),Yn={class:"base"},Gn=s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}},null,-1),Pn=s("span",{class:"mord mathnormal",style:{"margin-right":"0.0037em"}},"α",-1),Un=s("span",{class:"mord mathnormal"},"G",-1),Jn=s("span",{class:"mopen"},"(",-1),jn={class:"mord accent"},In={class:"vlist-t"},On={class:"vlist-r"},Qn={class:"vlist",style:{height:"0.714em"}},Wn=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w")],-1),Zn={style:{top:"-3em"}},$n=s("span",{class:"pstrut",style:{height:"3em"}},null,-1),sa={class:"accent-body",style:{left:"-0.1522em"}},na={class:"overlay",style:{height:"0.714em",width:"0.471em"}},aa={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},ta=s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1),ea=[ta],la=s("span",{class:"mclose"},")",-1),oa=s("code",null,"linear_model.Ridge",-1),ia={class:"katex"},ca=s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"G"),s("mo",{stretchy:"false"},"("),s("mover",{accent:"true"},[s("mi",null,"w"),s("mo",null,"⃗")]),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("msubsup",null,[s("mrow",null,[s("mo",{fence:"true"},"∥"),s("mtable",{rowspacing:"0.16em",columnalign:"center",columnspacing:"1em"},[s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"false"},[s("mover",{accent:"true"},[s("mi",null,"w"),s("mo",null,"⃗")])])])])]),s("mo",{fence:"true"},"∥")]),s("mn",null,"2"),s("mn",null,"2")])]),s("annotation",{encoding:"application/x-tex"},"G(\\vec{w})=\\begin{Vmatrix}\\vec{w}\\end{Vmatrix}_2^2")])])],-1),pa={class:"katex-html","aria-hidden":"true"},ra={class:"base"},da=s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}},null,-1),ua=s("span",{class:"mord mathnormal"},"G",-1),ma=s("span",{class:"mopen"},"(",-1),ha={class:"mord accent"},_a={class:"vlist-t"},va={class:"vlist-r"},ka={class:"vlist",style:{height:"0.714em"}},ga=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w")],-1),ya={style:{top:"-3em"}},ba=s("span",{class:"pstrut",style:{height:"3em"}},null,-1),wa={class:"accent-body",style:{left:"-0.1522em"}},xa={class:"overlay",style:{height:"0.714em",width:"0.471em"}},fa={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},Ea=s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1),Ba=[Ea],Aa=s("span",{class:"mclose"},")",-1),Ma=s("span",{class:"mspace",style:{"margin-right":"0.2778em"}},null,-1),qa=s("span",{class:"mrel"},"=",-1),za=s("span",{class:"mspace",style:{"margin-right":"0.2778em"}},null,-1),Ca={class:"base"},Sa=s("span",{class:"strut",style:{height:"1.4537em","vertical-align":"-0.3997em"}},null,-1),Ka={class:"minner"},Xa={class:"minner"},La=a(`<span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-2.85em;"><span class="pstrut" style="height:3.2em;"></span><span style="width:0.556em;height:1.200em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.556em" height="1.200em" viewBox="0 0 556 1200"><path d="M145 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M188 15 H145 v585 v0 v585 h43z
M367 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M410 15 H367 v585 v0 v585 h43z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span></span>`,1),Fa={class:"mord"},Da={class:"mtable"},Va={class:"col-align-c"},Ra={class:"vlist-t vlist-t2"},Ha={class:"vlist-r"},Na={class:"vlist",style:{height:"0.85em"}},Ta={style:{top:"-3.01em"}},Ya=s("span",{class:"pstrut",style:{height:"3em"}},null,-1),Ga={class:"mord"},Pa={class:"mord accent"},Ua={class:"vlist-t"},Ja={class:"vlist-r"},ja={class:"vlist",style:{height:"0.714em"}},Ia=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w")],-1),Oa={style:{top:"-3em"}},Qa=s("span",{class:"pstrut",style:{height:"3em"}},null,-1),Wa={class:"accent-body",style:{left:"-0.1522em"}},Za={class:"overlay",style:{height:"0.714em",width:"0.471em"}},$a={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},st=s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1),nt=[st],at=s("span",{class:"vlist-s"},"​",-1),tt=s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.35em"}},[s("span")])],-1),et=a(`<span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-2.85em;"><span class="pstrut" style="height:3.2em;"></span><span style="width:0.556em;height:1.200em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.556em" height="1.200em" viewBox="0 0 556 1200"><path d="M145 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M188 15 H145 v585 v0 v585 h43z
M367 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M410 15 H367 v585 v0 v585 h43z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span></span>`,1),lt=a('<span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.054em;"><span style="top:-2.3003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.3029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3997em;"><span></span></span></span></span></span>',1),ot=s("code",null,"linear_model.Lasso",-1),it={class:"katex"},ct=s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"G"),s("mo",{stretchy:"false"},"("),s("mover",{accent:"true"},[s("mi",null,"w"),s("mo",null,"⃗")]),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("msub",null,[s("mrow",null,[s("mo",{fence:"true"},"∥"),s("mtable",{rowspacing:"0.16em",columnalign:"center",columnspacing:"1em"},[s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"false"},[s("mover",{accent:"true"},[s("mi",null,"w"),s("mo",null,"⃗")])])])])]),s("mo",{fence:"true"},"∥")]),s("mn",null,"1")])]),s("annotation",{encoding:"application/x-tex"},"G(\\vec{w})=\\begin{Vmatrix}\\vec{w}\\end{Vmatrix}_1")])])],-1),pt={class:"katex-html","aria-hidden":"true"},rt={class:"base"},dt=s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}},null,-1),ut=s("span",{class:"mord mathnormal"},"G",-1),mt=s("span",{class:"mopen"},"(",-1),ht={class:"mord accent"},_t={class:"vlist-t"},vt={class:"vlist-r"},kt={class:"vlist",style:{height:"0.714em"}},gt=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w")],-1),yt={style:{top:"-3em"}},bt=s("span",{class:"pstrut",style:{height:"3em"}},null,-1),wt={class:"accent-body",style:{left:"-0.1522em"}},xt={class:"overlay",style:{height:"0.714em",width:"0.471em"}},ft={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},Et=s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1),Bt=[Et],At=s("span",{class:"mclose"},")",-1),Mt=s("span",{class:"mspace",style:{"margin-right":"0.2778em"}},null,-1),qt=s("span",{class:"mrel"},"=",-1),zt=s("span",{class:"mspace",style:{"margin-right":"0.2778em"}},null,-1),Ct={class:"base"},St=s("span",{class:"strut",style:{height:"1.2497em","vertical-align":"-0.3997em"}},null,-1),Kt={class:"minner"},Xt={class:"minner"},Lt=a(`<span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-2.85em;"><span class="pstrut" style="height:3.2em;"></span><span style="width:0.556em;height:1.200em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.556em" height="1.200em" viewBox="0 0 556 1200"><path d="M145 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M188 15 H145 v585 v0 v585 h43z
M367 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M410 15 H367 v585 v0 v585 h43z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span></span>`,1),Ft={class:"mord"},Dt={class:"mtable"},Vt={class:"col-align-c"},Rt={class:"vlist-t vlist-t2"},Ht={class:"vlist-r"},Nt={class:"vlist",style:{height:"0.85em"}},Tt={style:{top:"-3.01em"}},Yt=s("span",{class:"pstrut",style:{height:"3em"}},null,-1),Gt={class:"mord"},Pt={class:"mord accent"},Ut={class:"vlist-t"},Jt={class:"vlist-r"},jt={class:"vlist",style:{height:"0.714em"}},It=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w")],-1),Ot={style:{top:"-3em"}},Qt=s("span",{class:"pstrut",style:{height:"3em"}},null,-1),Wt={class:"accent-body",style:{left:"-0.1522em"}},Zt={class:"overlay",style:{height:"0.714em",width:"0.471em"}},$t={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},se=s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1),ne=[se],ae=s("span",{class:"vlist-s"},"​",-1),te=s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.35em"}},[s("span")])],-1),ee=a(`<span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-2.85em;"><span class="pstrut" style="height:3.2em;"></span><span style="width:0.556em;height:1.200em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.556em" height="1.200em" viewBox="0 0 556 1200"><path d="M145 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M188 15 H145 v585 v0 v585 h43z
M367 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M410 15 H367 v585 v0 v585 h43z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span></span>`,1),le=a('<span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.0514em;"><span style="top:-2.3003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3997em;"><span></span></span></span></span></span>',1),oe=s("li",null,[n("弹性网络回归 "),s("code",null,"linear_model.ElasticNet"),n(" 结合了 L1, L2 两种正则化方式的回归, 对于多属性问题有专用模型 "),s("code",null,"linear_model.MultiTaskElasticNet")],-1),ie=s("p",null,"将回归模型用于二分类",-1),ce=s("code",null,"linear_model.LogisticRegression",-1),pe={class:"katex"},re=s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"y"),s("mo",null,"="),s("mi",{mathvariant:"normal"},"sigmoid"),s("mo",null,"⁡"),s("mo",{stretchy:"false"},"("),s("msup",null,[s("mover",{accent:"true"},[s("mi",null,"w"),s("mo",null,"⃗")]),s("mi",null,"T")]),s("mover",{accent:"true"},[s("mi",null,"x"),s("mo",null,"⃗")]),s("mo",null,"+"),s("mi",null,"b"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"y=\\operatorname{sigmoid}(\\vec{w}^T\\vec{x}+b)")])])],-1),de={class:"katex-html","aria-hidden":"true"},ue=a('<span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span>',1),me={class:"base"},he=s("span",{class:"strut",style:{height:"1.0913em","vertical-align":"-0.25em"}},null,-1),_e=s("span",{class:"mop"},[s("span",{class:"mord mathrm"},"sigmoid")],-1),ve=s("span",{class:"mopen"},"(",-1),ke={class:"mord"},ge={class:"mord accent"},ye={class:"vlist-t"},be={class:"vlist-r"},we={class:"vlist",style:{height:"0.714em"}},xe=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w")],-1),fe={style:{top:"-3em"}},Ee=s("span",{class:"pstrut",style:{height:"3em"}},null,-1),Be={class:"accent-body",style:{left:"-0.1522em"}},Ae={class:"overlay",style:{height:"0.714em",width:"0.471em"}},Me={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},qe=s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1),ze=[qe],Ce=a('<span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span>',1),Se={class:"mord accent"},Ke={class:"vlist-t"},Xe={class:"vlist-r"},Le={class:"vlist",style:{height:"0.714em"}},Fe=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"x")],-1),De={style:{top:"-3em"}},Ve=s("span",{class:"pstrut",style:{height:"3em"}},null,-1),Re={class:"accent-body",style:{left:"-0.2077em"}},He={class:"overlay",style:{height:"0.714em",width:"0.471em"}},Ne={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},Te=s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1),Ye=[Te],Ge=s("span",{class:"mspace",style:{"margin-right":"0.2222em"}},null,-1),Pe=s("span",{class:"mbin"},"+",-1),Ue=s("span",{class:"mspace",style:{"margin-right":"0.2222em"}},null,-1),Je=s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"b"),s("span",{class:"mclose"},")")],-1),je={href:"https://mp.weixin.qq.com/s/mr83EK24S94b_UUlecyqlA",target:"_blank",rel:"noopener noreferrer"},Ie=s("h2",{id:"支持向量机",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#支持向量机","aria-hidden":"true"},"#"),n(" 支持向量机")],-1),Oe={href:"https://scikit-learn.org/stable/modules/svm.html#svm",target:"_blank",rel:"noopener noreferrer"},Qe=a('<p>支持向量机相关模块 <code>from sklearn import svm</code></p><p>支持向量机能较好地应用于高维 (多特征样本) 的分类 (Classification), 回归, 异常检测问题, 且预测效率较高</p><p>但要求有足够的训练样本, 至少应远多于样本特征</p><h3 id="支持向量机原理" tabindex="-1"><a class="header-anchor" href="#支持向量机原理" aria-hidden="true">#</a> 支持向量机原理</h3><p>支持向量机分类中, 通过训练样本确定各个之间的最佳边界, 预测时仅需确定样本所在分解位置即可得到样本分类</p><p>支持向量机回归中, 通过训练样本确定一个能最好包容训练样本的管道, 以管道中心曲线作为回归结果</p><p>支持向量机问题改进</p><ul><li>对于非线性问题, 支持向量机通过核函数重定义两个向量点乘实现向量升维以解决非线性 (默认核函数只能产生线性的边界)</li><li>对于离群点问题 (两个样本之间混杂), 支持向量机通过引入松弛变量, 允许划分边界存在误差</li></ul><h3 id="支持向量分类使用" tabindex="-1"><a class="header-anchor" href="#支持向量分类使用" aria-hidden="true">#</a> 支持向量分类使用</h3><p>创建非线性支持向量分类模型<br><code>svc = svm.SVC(*, C = 1, kernel = &quot;rbf&quot;, probability = False)</code></p>',10),We=s("code",null,"kernel",-1),Ze=s("li",null,[s("code",null,"rbf"),n(" 高斯核函数 (径向基核函数), 能升维至无穷, 常用于训练样本较少的非线性问题")],-1),$e=s("li",null,[s("code",null,"poly"),n(" 多项式核函数, 能进行有限升维, 常用于处理低维简单数据")],-1),sl=s("li",null,[n("线性核函数, 建议使用专门的模型 "),s("code",null,"svm.LinearSVC")],-1),nl={href:"https://scikit-learn.org/stable/auto_examples/svm/plot_iris_svc.html#sphx-glr-auto-examples-svm-plot-iris-svc-py",target:"_blank",rel:"noopener noreferrer"},al=s("li",null,[s("code",null,"gamma"),n(" 核函数系数 "),s("ul",null,[s("li",null,"取值越大单个样本的影响越小, 边界越复杂越容易过拟合"),s("li",null,[n("可传入字符串 "),s("code",null,"scale"),n(", 通过样本自动判断")])])],-1),tl=s("code",null,"C",-1),el=s("li",null,"取值越大, 越不容许分类存在错误因此越容易过拟合, 越小则相反",-1),ll={href:"https://scikit-learn.org/stable/auto_examples/svm/plot_svm_scale_c.html#sphx-glr-auto-examples-svm-plot-svm-scale-c-py",target:"_blank",rel:"noopener noreferrer"},ol=s("li",null,[s("code",null,"degree = 3"),n(" 多项式核函数的次数, 仅用于多项式核函数")],-1),il=s("li",null,[s("code",null,"probability"),n(" 通过训练多个 SVC 交叉验证, 从而使模型获得输出分类概率的能力, 但将降低训练速度")],-1),cl=s("p",null,[n("创建线性支持向量分类模型"),s("br"),s("code",null,"svm.LinearSVC(*, C = 1, loss = 'squared_hinge')")],-1),pl=s("ul",null,[s("li",null,[s("code",null,"C"),n(" 惩罚系数, 含义同上")]),s("li",null,[s("code",null,"loss"),n(" 损失函数, 传入字符串表示 "),s("ul",null,[s("li",null,[s("code",null,"squared_hinge"),n(" 默认损失函数")]),s("li",null,[s("code",null,"hinge"),n(" 具有更好性能的 Hinge 损失函数 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"Hinge"),s("mo",null,"⁡"),s("mo",{stretchy:"false"},"("),s("mi",null,"t"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mi",null,"max"),s("mo",null,"⁡"),s("mo",{stretchy:"false"},"("),s("mn",null,"0"),s("mo",{separator:"true"},","),s("mn",null,"1"),s("mo",null,"−"),s("mi",null,"t"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"\\operatorname{Hinge}(t)=\\max(0,1-t)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mop"},[s("span",{class:"mord mathrm"},"Hinge")]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mop"},"max"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"0"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mclose"},")")])])])])])]),s("li",null,"虽然无法解决非线性问题, 但该模型经过特殊优化, 具有远超一般模型的性能"),s("li",null,"该模型用于特征极多 (不再需要升维), 训练样本极多且追求效率的问题")],-1),rl=a(`<p>通常建议使用支持向量机时, 先使用<a href="#%E6%95%B0%E6%8D%AE%E6%B5%81%E6%B0%B4%E7%BA%BF">数据流水线</a>将输入的数据标准化 (<code>StandardScaler</code>) 以得到更好的效果, 一般有代码</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>svm <span class="token keyword">import</span> SVC
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>pipeline <span class="token keyword">import</span> Pipeline

rbf_kernel_svm_clf <span class="token operator">=</span> Pipeline<span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">&quot;scaler&quot;</span><span class="token punctuation">,</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">&quot;svm_clf&quot;</span><span class="token punctuation">,</span> SVC<span class="token punctuation">(</span>kernel<span class="token operator">=</span><span class="token string">&quot;rbf&quot;</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> C<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
rbf_kernel_svm_clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="支持向量回归使用" tabindex="-1"><a class="header-anchor" href="#支持向量回归使用" aria-hidden="true">#</a> 支持向量回归使用</h3>`,3),dl=s("p",null,[n("在支持向量回归中, 还需要给定超参数 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"ε")]),s("annotation",{encoding:"application/x-tex"},"\\varepsilon")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"ε")])])]),n(" 以确定拟合管道的宽度")],-1),ul=s("ul",null,[s("li",null,"当样本落在管道内时认为是正常回归误差, 对回归曲线没有影响"),s("li",null,"当样本在管道外时, 将影响回归曲线的形状, 成为支持向量"),s("li",null,[n("因此一般超参数 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"ε")]),s("annotation",{encoding:"application/x-tex"},"\\varepsilon")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"ε")])])]),n(" 即允许的回归误差")])],-1),ml=a('<p>创建非线性支持向量回归模型 <code>svc = svm.SVC(*, C = 1, kernel = &quot;rbf&quot;, epsilon = 0.1)</code></p><ul><li><code>epsilon</code> 浮点数, 管道宽度超参数</li><li>其余参数含义与 <a href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E5%88%86%E7%B1%BB%E4%BD%BF%E7%94%A8">SVC</a> 相同</li></ul><p>创建线性支持向量回归模型 <code>svc = svm.LinearSVC(*, C = 1, loss = &#39;squared_hinge&#39;, epsilon = 0.0)</code></p><ul><li><code>epsilon</code> 浮点数, 管道宽度超参数</li><li>其余参数含义与 <a href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E5%88%86%E7%B1%BB%E4%BD%BF%E7%94%A8">SVC</a> 相同</li></ul><h2 id="决策树模型" tabindex="-1"><a class="header-anchor" href="#决策树模型" aria-hidden="true">#</a> 决策树模型</h2>',5),hl={href:"https://scikit-learn.org/stable/modules/tree.html#decision-trees",target:"_blank",rel:"noopener noreferrer"},_l=a('<p>决策树相关模块 <code>from sklearn import tree</code></p><p>决策树同样能够用于分类与回归问题, 且具有特点</p><ul><li>能够拟合复杂的数据集</li><li>样本特征数据几乎不需要任何预处理</li><li>具有较好的可解释性</li></ul><h3 id="决策树原理" tabindex="-1"><a class="header-anchor" href="#决策树原理" aria-hidden="true">#</a> 决策树原理</h3><p>决策树的基本原理即</p><ul><li>决策树通过贪心算法 (CART 训练算法), 以特定指标 (超参数) 将样本以其中一个特征划分为类间区别最大, 类内区别最小的两份, 以此确定二叉树的一个节点</li><li>通过转换划分特征, 不断二分划分样本即可得到一个二叉树结构</li><li>当样本无法再划分时, 将成为叶子节点, 通过剩余样本中类别做多的作为满足此条件时的样本类别</li><li>对于决策树回归, 即将叶子节点改为输出属性, 通过使剩余样本的均方根误差最小确定</li></ul><p>根据其原理可知, 决策树也存在部分问题</p><ul><li>决策树的划分边界通常都是正交的 (即分类边界或回归曲线呈折线形), 因此可能需要 <a href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86">PCA</a> 处理, 提取输入特征中的主成分</li><li>决策树必须要经过正则化处理 (限制树规模), 否则十分容易过拟合</li><li>根据算法不同决策树的形状可能不同, 如果要得到最优决策树可能需要较大的训练时间</li></ul><h3 id="决策树使用" tabindex="-1"><a class="header-anchor" href="#决策树使用" aria-hidden="true">#</a> 决策树使用</h3><p>创建决策树分类模型<br><code>tree.DecisionTreeClassifier(*, criterion = &#39;gini&#39;, max_depth = None, min_samples_split = 2, min_samples_leaf = 1, random_state = None)</code></p>',10),vl=a("<li><code>criterion</code> 字符串, 划分样本区别判别方法, 可用的有 <ul><li><code>gini</code> 基于基尼不纯度划分 (一般使用此方法即可)</li><li><code>entropy</code> 基于熵划分</li></ul></li><li><code>random_state</code> 整数, 生成决策树的随机种子, 可确定此参数保证每次生成相同的决策树</li><li><code>max_depth</code> 决策树的最大深度, 不包括根节点 (增大时可提升非线性性), 过拟合时, 可设置一个较小值</li><li><code>min_samples_split</code> 一个划分中最小样本数, 传入整数时即样本数, 传入浮点数时表示相对总样本数的比值</li><li><code>min_samples_leaf</code> 一个叶子节点中剩余的最小样本数 (减小时可平滑边界), 通过该参数能够有效平滑决策树回归曲线, 同样可传入整数与浮点数 (含义同上)</li>",5),kl={href:"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#decisiontreeclassifier",target:"_blank",rel:"noopener noreferrer"},gl=a(`<p>创建决策树回归模型<br><code>tree.DecisionTreeClassifier(*, criterion = &#39;squared_error&#39;, max_depth = None, min_samples_split = 2, min_samples_leaf = 1)</code></p><ul><li><code>criterion</code> 字符串, 划分样本区别判别方法, 常用的有 <ul><li><code>squared_error</code> 基于均方误差划分</li><li><code>friedman_mse</code> 基于 Friedman 不纯度划分</li></ul></li><li><code>max_depth, min_samples_split, min_samples_leaf</code> 正则化超参数, 含义同决策树分类模型</li></ul><p>绘制决策树 (对于决策树的具体形状可通过以下函数绘制)<br><code>tree.plot_tree(decision_tree, *, max_depth = None, filled = False, ax = None)</code></p><ul><li><code>decision_tree</code> 被绘制的决策树模型, 需要经过训练</li><li><code>max_depth</code> 决策树绘制深度, 剩余部分将被忽略</li><li><code>filled</code> 是否用颜色填充节点</li><li><code>ax</code> 绘制决策树的图像对象</li><li>绘制的决策树中, 将通过方框分别表示 <ul><li>节点的决策条件</li><li>节点划分样本的区分程度</li><li>节点输入的样本个数</li><li>节点输入的样本中, 各种分类下的样本数 (当优势类别越显著, 方框颜色越深)</li></ul></li></ul><h3 id="决策树调整" tabindex="-1"><a class="header-anchor" href="#决策树调整" aria-hidden="true">#</a> 决策树调整</h3><p>决策树模型的调整一般需要配合<a href="#%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF">学习曲线</a>判断是否过拟合, 例如以下示例代码</p><ul><li>当决策树中有样本量极小的叶子节点时, 可增大 <code>min_samples_leaf</code></li><li>当决策树不完全时, 可适当减小 <code>max_depth</code></li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> LearningCurveDisplay
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> tree
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split

fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
axes <span class="token operator">=</span> fig<span class="token punctuation">.</span>subplot_mosaic<span class="token punctuation">(</span><span class="token string">&quot;AB&quot;</span><span class="token punctuation">)</span>

 导入数据
X<span class="token punctuation">,</span> Y <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_breast_cancer<span class="token punctuation">(</span>return_X_y <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
trX<span class="token punctuation">,</span> ttX<span class="token punctuation">,</span> trY<span class="token punctuation">,</span> ttY <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> test_size <span class="token operator">=</span> <span class="token number">0.3</span><span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">114514</span><span class="token punctuation">)</span>

tree_cls <span class="token operator">=</span> tree<span class="token punctuation">.</span>DecisionTreeClassifier<span class="token punctuation">(</span>max_depth <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span> min_samples_leaf <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">114514</span><span class="token punctuation">)</span>
tree_cls<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>trX<span class="token punctuation">,</span> trY<span class="token punctuation">)</span>
tree<span class="token punctuation">.</span>plot_tree<span class="token punctuation">(</span>tree_cls<span class="token punctuation">,</span> ax <span class="token operator">=</span> axes<span class="token punctuation">[</span><span class="token string">&quot;A&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> filled <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> max_depth <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
LearningCurveDisplay<span class="token punctuation">.</span>from_estimator<span class="token punctuation">(</span>tree_cls<span class="token punctuation">,</span> X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> ax <span class="token operator">=</span> axes<span class="token punctuation">[</span><span class="token string">&quot;B&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

axes<span class="token punctuation">[</span><span class="token string">&quot;A&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">&quot;决策树&quot;</span><span class="token punctuation">)</span>
axes<span class="token punctuation">[</span><span class="token string">&quot;B&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">&quot;训练曲线&quot;</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>运行结果</p><figure><img src="`+p+'" alt="" tabindex="0"><figcaption></figcaption></figure><h2 id="集成学习" tabindex="-1"><a class="header-anchor" href="#集成学习" aria-hidden="true">#</a> 集成学习</h2>',11),yl={href:"https://scikit-learn.org/stable/modules/ensemble.html",target:"_blank",rel:"noopener noreferrer"},bl=a('<p>集成学习相关模块 <code>from sklearn import ensemble</code></p><p>在分类模型中<br> 理论上, 只要模型的性能优于随机选择, 且模型之间相互独立, 通过多个独立分类模型同时预测表决将显著提升模型的准确率</p><p>在回归模型类似, 但使用平均值等方法集成各个模型的结果</p><p>将这类继承了其他模型的模型, 成为集成学习</p><h3 id="投票分类器" tabindex="-1"><a class="header-anchor" href="#投票分类器" aria-hidden="true">#</a> 投票分类器</h3><p>基本投票分类器 <code>VotingClassifier</code><br> 即最基本的集成学习, 通过多个独立模型间投票决定最终输出</p><ul><li>超参数 <code>estimators</code> 即一个以元组 <code>(name, estimator)</code> 为元素的数组, 体现投票器内的所有模型</li><li>超参数 <code>voting</code> 字符串, 反映了投票表决方法, 可以是以下值 <ul><li><code>hard</code> 硬投票, 即得票多的类别作为最终结果</li><li><code>soft</code> 软投票, 即根据模型预测的概率为投票权重, 有更高的准确率但要求模型有预测概率的能力, 即有方法 <a href="#scikit-learn-%E6%A8%A1%E5%9E%8B%E7%89%B9%E7%82%B9">predict_proba</a></li></ul></li><li>类似的还有投票回归 <code>VotingRegressor</code></li></ul><h3 id="自举汇聚法" tabindex="-1"><a class="header-anchor" href="#自举汇聚法" aria-hidden="true">#</a> 自举汇聚法</h3><p>自举汇聚法 (Bagging 方法) <code>BaggingClassifier</code><br> 同样是投票分类, 但集成的模型相同, 只是分别随机采用部分训练样本来保证模型间的独立性</p><ul><li>超参数 <code>estimators</code> 即投票器中的基本模型</li><li>超参数 <code>n_estimators</code> 整数, 即投票器中的模型数</li><li>超参数 <code>max_samples</code> 浮点数, 即训练时单个模型最多接收的训练样本占总样本的比例 (称为随即补丁法)</li><li>超参数 <code>max_features</code> 浮点数, 即训练单个模型时仅提取部分特征占总特征的比例 (一般仅用于图片等高维特征, 称为随机子空间法)</li><li>通常该方法训练产生的模型性能与单个模型相近, 但稳定性与泛化性将得到极大提升, 且可并行训练</li><li>类似的还有回归模型 <code>BaggingRegressor</code></li></ul><h3 id="随机森林" tabindex="-1"><a class="header-anchor" href="#随机森林" aria-hidden="true">#</a> 随机森林</h3><p>随机森林 <code>RandomForestClassifier</code></p><ul><li>即以<a href="#%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B">决策树</a>为集成模型的<a href="#%E8%87%AA%E4%B8%BE%E6%B1%87%E8%81%9A%E6%B3%95">自举汇聚法</a></li><li>模型同时具有<a href="#%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B">决策树</a>与<a href="#%E8%87%AA%E4%B8%BE%E6%B1%87%E8%81%9A%E6%B3%95">自举汇聚法</a>的超参数 <ul><li>没有超参数 <code>max_samples</code>, 强制使用随机子空间法</li><li>样本足够时, 模型数 <code>n_estimators</code> 可能达 100 个以上, 需要通过<a href="#%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2">网格搜索</a>确定超参数</li></ul></li><li>一般仅限制决策树的 <code>max_leaf_nodes</code> 超参数, 使集成的每个决策树具有尽可能多的多样性</li><li>由于决策树足够多, 因此对最优性没有特别高的要求, 但希望每个决策树都尽可能不同, 因此有变种极端随机森林 <code>ExtraTreesClassifier</code> (超参数相同, 一般需要交叉验证确定其与一般随机森林何者性能更好)</li><li>同样有随机森林回归 <code>RandomForestRegressor</code> 与极端随机森林回归 <code>ExtraTreesRegressor</code></li><li>在模型训练后, 通过随机森林模型的成员 <code>feature_importances_</code> 还可以得到各个特征的重要性</li></ul><h3 id="自适应提升法" tabindex="-1"><a class="header-anchor" href="#自适应提升法" aria-hidden="true">#</a> 自适应提升法</h3>',14),wl={href:"https://scikit-learn.org/stable/modules/ensemble.html#adaboost",target:"_blank",rel:"noopener noreferrer"},xl=a('<p>自适应提升法 <code>AdaBoostClassifier</code><br> 与<a href="#%E8%87%AA%E4%B8%BE%E6%B1%87%E8%81%9A%E6%B3%95">自举汇聚法</a>类似, 但是训练时各个模型之间呈串联关系, 即第一个模型训练后预测错误的样本将以更大的权重传入下一个模型训练</p><ul><li>超参数 <code>estimators</code> 即投票器中的基本模型, 默认为单层 (<code>max_depth=1</code>) 的<a href="#%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B">决策树</a></li><li>超参数 <code>n_estimators</code> 整数, 即投票器中的模型数</li><li>超参数 <code>learning_rate</code> 浮点数, 传递错误样本的学习率</li><li>同样有用于回归问题的模型 <code>AdaBoostRegressor</code></li><li>使用 AdaBoost 不容易出现过拟合问题, 但是需要的训练时间较长且无法并行训练</li></ul><h2 id="k-均值聚类" tabindex="-1"><a class="header-anchor" href="#k-均值聚类" aria-hidden="true">#</a> K 均值聚类</h2>',3),fl={href:"https://scikit-learn.org/stable/modules/clustering.html#k-means",target:"_blank",rel:"noopener noreferrer"},El=a('<p>聚类相关模块 <code>from sklearn import cluster</code></p><p>K 均值聚类属于无监督学习模型, 能够将相似的样本分类到集群中<br> 聚类 (Clustering) 可用于数据分析, 数据预处理 (降维), 异常检测 (检测离群点), 半监督学习 (标签传播)</p><p>与一般监督学习不同</p><ul><li>模型除了 <code>fit, predict</code> 方法, 还有 <code>fit_predict</code> 方法, 该方法接收特征数组 <code>X</code>, 训练结果的输出分类数组 <code>y</code>, 以此反应聚类结果</li><li>模型的 <code>fit</code> 方法将忽略属性数组 <code>y</code>, 仅训练确定集群特征 (集群中心点), 一般不使用</li><li>模型的 <code>predict</code> 方法将根据训练得到的集群特征确定输入样本属于哪个聚类</li></ul><h3 id="k-均值聚类原理" tabindex="-1"><a class="header-anchor" href="#k-均值聚类原理" aria-hidden="true">#</a> K 均值聚类原理</h3><p>K 均值聚类的基本原理为</p><ul><li>首先需要确定样本的集群数 K 这一超参数</li><li>随机将 K 个样本定位集群中心, 并将离中心最近的样本标记为一个集群</li><li>计算各个集群的平均值, 作为新的集群中心并迭代</li><li>当集群中心不再移动时, 完成聚类</li></ul><p>根据原理可得 K 均值聚类有特点</p><ul><li>通过最终集群中心与集群中点距离的均方差衡量聚类效果, 成为惯性 (<code>scikit-learn</code> 中使用负惯性为指标, 越大越好)</li><li>选择不同的初始点将得到效果完全不同的结果, 一般使用 <code>K-Means++</code> 算法逐个选择相距较远的初始点, 保证得到最优解</li><li>此外, 集群数 K 的选择对最终效果也有较大的影响, 但惯性总是随 K 增大而减小, 因此一般 <ul><li>首先绘制出 K 与惯性的曲线, 并找到其中的肘点 (两侧斜率快速变化点)</li><li>改用轮廓分数 <code>silhouette_score</code> 作为评分标准, 绘制肘点附近 K 与轮廓分输的曲线, 以轮廓分输最高的作为采用的 K</li></ul></li><li>K 均值聚类虽然有很快的训练与预测速度, 但是对于椭圆形等异性分布的聚类效果较差, 应对特征进行<a href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86">标准化</a>或选择其他模型如 DBSCAN</li></ul><h3 id="k-均值聚类应用" tabindex="-1"><a class="header-anchor" href="#k-均值聚类应用" aria-hidden="true">#</a> K 均值聚类应用</h3><p>简单图像分割</p><ul><li>将彩色图像每一像素视为一个三元素向量 (RGB) 样本</li><li>通过 K 均值聚类训练图像像素, 将各个像素分组聚类, 实现图像分割</li><li>读取 K 均值聚类训练的聚类中心, 体现了各个像素组的代表颜色</li><li>保留所需的代表颜色, 实现对图像特定区域的提取 (二值化), 再进行下一步处理</li></ul><p>半监督学习 (标签传播)</p>',13),Bl=s("li",null,"对于所有样本, 目前仅提取了特征, 还没有对类别标记",-1),Al=s("li",null,"首先使用 K 均值聚类对样本特征聚类 (通常聚类数远多于类别数)",-1),Ml=s("li",null,"对每个聚类中心进行人工标记, 从而确定聚类与类别之间的映射关系",-1),ql=s("li",null,"通过这一映射关系, 传播到所有样本上, 完成对样本的标记",-1),zl=s("li",null,"为了更高的准确性, 有时仅传播标记离中心最近的部分样本 (如最近的 20%), 舍弃其余样本",-1),Cl={href:"https://scikit-learn.org/stable/modules/semi_supervised.html",target:"_blank",rel:"noopener noreferrer"},Sl=a(`<h3 id="k-均值聚类使用示例" tabindex="-1"><a class="header-anchor" href="#k-均值聚类使用示例" aria-hidden="true">#</a> K 均值聚类使用示例</h3><p>创建 K 均值聚类模型<br><code>cluster.KMeans(n_clusters = 8, random_state = None)</code></p><ul><li><code>n_clusters</code> 聚类集群数</li><li><code>random_state</code> 选择初始中心点的随机种子</li></ul><p>创建小批量 K 均值聚类 <code>cluster.MiniBatchKMeans(n_clusters = 8, random_state = None)</code></p><ul><li><code>n_clusters</code> 聚类集群数</li><li><code>random_state</code> 选择初始中心点的随机种子</li><li>相比一般 K 均值聚类训练速度更快, 但模型性能较差, 用于 K 极大的情况如 <code>K&gt;20</code>, 或样本特征维度极大的情况如图片</li></ul><p>验证 K 均值聚类效果<br><code>silhouette_samples(X, labels)</code></p><ul><li><code>X</code> 样本特征数组</li><li><code>labels</code> 样本的聚类标签数组, 可通过模型的 <a href="#k-%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB">fit_predict</a> 方法得到</li><li>返回值为一个浮点数, 越大聚类分类效果越好</li></ul><h3 id="k-均值聚类使用示例-1" tabindex="-1"><a class="header-anchor" href="#k-均值聚类使用示例-1" aria-hidden="true">#</a> K 均值聚类使用示例</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> cluster
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> silhouette_score

fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
axes <span class="token operator">=</span> fig<span class="token punctuation">.</span>subplot_mosaic<span class="token punctuation">(</span><span class="token string">&quot;AB;CC&quot;</span><span class="token punctuation">)</span>

 创建随机数据
X<span class="token punctuation">,</span> Y <span class="token operator">=</span> datasets<span class="token punctuation">.</span>make_classification<span class="token punctuation">(</span>
    n_features <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span> n_redundant <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> n_informative <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span> 
    n_classes <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> n_clusters_per_class <span class="token operator">=</span> <span class="token number">1</span>
<span class="token punctuation">)</span>
X <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span>

k_range <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span>
sh_score <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>k_range<span class="token punctuation">)</span><span class="token punctuation">)</span>

 遍历不同 K 值的聚类效果
<span class="token keyword">for</span> i<span class="token punctuation">,</span> k <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>k_range<span class="token punctuation">)</span><span class="token punctuation">:</span>
    km_clu <span class="token operator">=</span> cluster<span class="token punctuation">.</span>KMeans<span class="token punctuation">(</span>k<span class="token punctuation">)</span>
    sh_score<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> silhouette_score<span class="token punctuation">(</span>X<span class="token punctuation">,</span> km_clu<span class="token punctuation">.</span>fit_predict<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span>
axes<span class="token punctuation">[</span><span class="token string">&quot;C&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>plot<span class="token punctuation">(</span>k_range<span class="token punctuation">,</span> sh_score<span class="token punctuation">,</span> marker <span class="token operator">=</span> <span class="token string">&#39;o&#39;</span><span class="token punctuation">)</span>
axes<span class="token punctuation">[</span><span class="token string">&quot;C&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">&quot;不同 K 值的 silhouette_score&quot;</span><span class="token punctuation">)</span>

k_opt <span class="token operator">=</span> k_range<span class="token punctuation">[</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>sh_score<span class="token punctuation">)</span><span class="token punctuation">]</span>
km_clu <span class="token operator">=</span> cluster<span class="token punctuation">.</span>KMeans<span class="token punctuation">(</span>k_opt<span class="token punctuation">)</span>

 使用 scatter 绘制样本在样本空间的分布
axes<span class="token punctuation">[</span><span class="token string">&quot;A&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c <span class="token operator">=</span> Y<span class="token punctuation">)</span>
axes<span class="token punctuation">[</span><span class="token string">&quot;A&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">&quot;样本分类&quot;</span><span class="token punctuation">)</span>

axes<span class="token punctuation">[</span><span class="token string">&quot;B&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c <span class="token operator">=</span> km_clu<span class="token punctuation">.</span>fit_predict<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span>
axes<span class="token punctuation">[</span><span class="token string">&quot;B&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;k = </span><span class="token interpolation"><span class="token punctuation">{</span>k_opt<span class="token punctuation">}</span></span><span class="token string"> 的聚类分类&quot;</span></span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span><span class="token string">&quot;sklearn_kmean.svg&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>代码运行效果</p><figure><img src="`+r+'" alt="" tabindex="0"><figcaption></figcaption></figure><h3 id="其他聚类算法" tabindex="-1"><a class="header-anchor" href="#其他聚类算法" aria-hidden="true">#</a> 其他聚类算法</h3>',12),Kl={href:"https://scikit-learn.org/stable/modules/clustering.html#overview-of-clustering-methods",target:"_blank",rel:"noopener noreferrer"},Xl=a('<ul><li>密度聚类 <code>DBSCAN</code><ul><li>假设同一集群中的样本间距离极小, 不同集群则相反</li><li>只能用于确定训练样本所在集群, 无法确定测试样本所在集群 (可通过 KNN 实现), 但可以分析出不属于任何集群的离群点</li><li>仅具有两个超参数 <ul><li><code>eps</code> 样本检测半径, 集群越密集, 取值越小</li><li><code>min_samples</code> 集群核心点在指定范围内的其他样本数, 集群越密集, 取值越大</li></ul></li></ul></li><li>高斯混合模型 <code>GaussianMixture</code><ul><li>与 K 均值聚类原理类似, 但在聚类时提取了更多信息</li><li>假设集群呈任意椭圆分布, 且能够预测测试样本属于哪个集群的概率 (软聚类)</li></ul></li></ul><h2 id="模型选择与评估" tabindex="-1"><a class="header-anchor" href="#模型选择与评估" aria-hidden="true">#</a> 模型选择与评估</h2><h3 id="k-折交叉验证" tabindex="-1"><a class="header-anchor" href="#k-折交叉验证" aria-hidden="true">#</a> K 折交叉验证</h3><p>K 折交叉验证的方法即</p><ul><li>对于给定的训练样本, 将其平均分为 K 份 (一般取 5 ~ 10, 将每份成为一个折叠), 将其中一份作为训练集, 其余 K - 1 份作为测试集</li><li>遍历每份数据, 分别作为训练集并在测试集上使用给定的评估指标进行评分, 得到一个大小为 K 的数组即各份的评估结果</li><li>通过评分的均值与方差, 可以确定模型的准确性与稳定性</li></ul><p>在 Scikit-Learn 中一般使用 <code>from sklearn.model_selection import cross_val_score</code> 导入 K 折交叉验证函数</p><p>对模型进行 K 折交叉验证<br><code>cross_val_score(estimator, X, y, *, scoring = None, cv = 5, verbose = 0)</code></p><ul><li><code>estimator</code> 用于验证的模型对象, 不需要经过训练</li><li><code>X</code> 所有训练样本组成的二维样本特征数组</li><li><code>y</code> 所有训练样本组成的一维样本属性数组</li><li><code>scoring</code> 评估指标, 一般为字符串, 如果取 <code>None</code> 则将使用模型自带的评估指标, 具体介绍见下</li><li><code>cv</code> 训练样本平分份数, 一般为整数</li><li><code>verbose</code> 是否打印详细验证过程</li></ul><p>Scikit-Learn 中常用的评估指标如下 (一般使用模型自带评估指标即可)</p>',9),Ll=s("li",null,"在 Scikit-Learn 的评估指标中, 一般为越大越好",-1),Fl={href:"https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter",target:"_blank",rel:"noopener noreferrer"},Dl=a("<li>分类问题评估指标 <ul><li><code>accuracy</code> 准确率, 即分类正确预测占全部预测的比值</li><li><code>f1</code> F1 分数, 精确率与召回率的调和平均值</li><li><code>roc_auc</code> ROC 曲线面积, 越接近 1 性能越好</li></ul></li><li>回归问题评估指标 <ul><li><code>neg_root_mean_squared_error</code> 负均方根误差, 越接近 0 效果越好</li><li><code>neg_mean_squared_error</code> 负均方误差, 越接近 0 效果越好</li><li><code>r2</code> 拟合相关系数, 越接近 1 效果越好</li></ul></li>",2),Vl=s("h3",{id:"网格搜索",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#网格搜索","aria-hidden":"true"},"#"),n(" 网格搜索")],-1),Rl=s("p",null,"网格搜索的方法即",-1),Hl=s("ul",null,[s("li",null,[n("网格搜索即给定一系列模型超参数以及数个测试值, 将这些超参数测试值任意组合即可得到 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mo",null,"∑"),s("msub",null,[s("mi",null,"n"),s("mi",null,"i")])]),s("annotation",{encoding:"application/x-tex"},"\\sum n_i")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mop op-symbol small-op",style:{position:"relative",top:"0em"}},"∑"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"n"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),n(" 组模型")]),s("li",null,[n("用这些超参数分别创建模型, 并使用 "),s("a",{href:"#k-%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"},"K 折交叉验证"),n("评估各个模型")]),s("li",null,"将其中表现最好的模型作为网格搜索的结果")],-1),Nl=a(`<p>在 Scikit-Learn 中一般使用 <code>from sklearn.model_selection import GridSearchCV</code> 导入网格搜索模型类</p><p>创建网格搜索模型<br><code>gsc = GridSearchCV(estimator, param_grid, *, scoring = None, cv = 5, verbose = 0, refit = True)</code></p><ul><li><code>estimator</code> 用于验证的模型对象 (仅指定部分超参数)</li><li><code>param_grid</code> 超参数字典, 为一个以字符串为键, 数组为值的字典 <ul><li>字典的键通常即实例化模型时, 需要的超参数名称</li><li>字典的值通常包含了所有用于测试的超参数值 <ul><li>初选时可以 10 为比的等比数列以确定超参数的数量级</li><li>对于字符串超参数, 允许以字符串为数组元素</li></ul></li></ul></li><li><code>refit</code> 是否在找出最好模型后, 立刻使用全部样本重新训练最好模型 (需要将网格搜索模型视为一个可用模型时使用)</li><li><code>scoring, cv, verbose</code> 交叉验证参数, 含义同 <a href="#k-%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81">cross_val_score()</a>, 其中 <code>scoring</code> 可以传入字符串列表表示同时使用多个评估指标</li></ul><p>网格搜索模型使用</p><ul><li><code>gsc.fit(X, y)</code> 使用给定的样本对网格搜索模型中所有模型进行训练 (仅经过该函数训练后, 才能确定最好的模型)</li><li><code>gsc.predict(X, y)</code> 将效果最好的模型用于预测, 因此网格搜索模型也可视为一个独立的模型使用, 且可以植入<a href="#%E6%95%B0%E6%8D%AE%E6%B5%81%E6%B0%B4%E7%BA%BF">数据流水线中</a></li><li><code>gsc.best_estimator_</code> 经训练得到的评估分数最好的模型对象</li><li><code>gsc.best_params_</code> 最好的模型对象使用的超参数</li><li><code>gsc.best_score_</code> 最好的模型对象的评估分数</li><li><code>gsc.cv_results_</code> 字典, 反应各个模型的 K 折交叉验证评估结果与训练时间等信息, 主要的键有 (字符串) <ul><li><code>mean_test_score</code> 交叉验证中, 模型的平均评估分数, 反应模型性能</li><li><code>std_test_score</code> 交叉验证中, 模型的评估分数标准差, 反应模型稳定性</li></ul></li></ul><p>当模型训练时间极长或需要搜索的超参数较多时, 可改用随机搜索对超参数进行粗选</p><ul><li>使用 <code>from sklearn.model_selection import RandomizedSearchCV</code> 导入网格搜索模型类</li><li>随机搜素模型的使用与网格搜索相同, 仅增加一个关键字参数 <code>n_iter = 10</code> 表示随机搜索次数</li></ul><h3 id="超参数调节曲线" tabindex="-1"><a class="header-anchor" href="#超参数调节曲线" aria-hidden="true">#</a> 超参数调节曲线</h3><p>用于调整单个超参数, 通过曲线直观反映超参数取不同值时 <a href="#k-%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81">K 折交叉验证</a>的表现</p><p>虽然 Scikit-Learn 提供了有关绘制超参数调节曲线的函数, 但使用较为困难<br> 可利用单参数的 <a href="#%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2">GridSearchCV()</a> 与 Matplotlib 手动绘制, 具体参考下方确定<a href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E5%9B%9E%E5%BD%92%E4%BD%BF%E7%94%A8">支持向量回归</a>超参数的代码</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>pipeline <span class="token keyword">import</span> Pipeline
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> GridSearchCV
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> svm

 导入数据
data<span class="token punctuation">,</span> target <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_diabetes<span class="token punctuation">(</span>return_X_y <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment">## 超参数初选</span>
 已固定的超参数
define_param <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">&quot;kernel&quot;</span><span class="token punctuation">:</span> <span class="token string">&#39;poly&#39;</span><span class="token punctuation">,</span>
    <span class="token string">&quot;degree&quot;</span><span class="token punctuation">:</span> <span class="token number">3</span>
<span class="token punctuation">}</span>
svm_grid_raw <span class="token operator">=</span> GridSearchCV<span class="token punctuation">(</span>svm<span class="token punctuation">.</span>SVR<span class="token punctuation">(</span><span class="token operator">**</span>define_param<span class="token punctuation">)</span><span class="token punctuation">,</span>
     通过以 <span class="token number">10</span> 为底的等比数列初选超参数<span class="token punctuation">,</span> 且应当避免数列中出现 <span class="token number">1</span>
    param_grid <span class="token operator">=</span> <span class="token punctuation">{</span> 
        <span class="token string">&quot;C&quot;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>logspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> base <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">&quot;epsilon&quot;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>logspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> base <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">)</span>
svm_grid_raw_pip <span class="token operator">=</span> Pipeline<span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">&quot;std&quot;</span><span class="token punctuation">,</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">&quot;grid_svm&quot;</span><span class="token punctuation">,</span> svm_grid_raw<span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
svm_grid_raw_pip<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>data<span class="token punctuation">,</span> target<span class="token punctuation">)</span>
raw_param <span class="token operator">=</span> svm_grid_raw_pip<span class="token punctuation">[</span><span class="token string">&quot;grid_svm&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>best_params_
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;raw params: </span><span class="token interpolation"><span class="token punctuation">{</span>raw_param<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>

<span class="token comment">## 进一步确定主要超参数 C</span>
 依然使用等比数列<span class="token punctuation">,</span> 但以初选数量级为基底
c_valid_list <span class="token operator">=</span> np<span class="token punctuation">.</span>logspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> base <span class="token operator">=</span> raw_param<span class="token punctuation">[</span><span class="token string">&quot;C&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
svm_valid_C <span class="token operator">=</span> GridSearchCV<span class="token punctuation">(</span>svm<span class="token punctuation">.</span>SVR<span class="token punctuation">(</span><span class="token operator">**</span>define_param<span class="token punctuation">,</span> epsilon <span class="token operator">=</span> raw_param<span class="token punctuation">[</span><span class="token string">&quot;epsilon&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     绘制超参数调节曲线时<span class="token punctuation">,</span> 一般仅能体现一个超参数的变化
    param_grid <span class="token operator">=</span> <span class="token punctuation">{</span> 
        <span class="token string">&quot;C&quot;</span><span class="token punctuation">:</span> c_valid_list<span class="token punctuation">,</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">)</span>
svm_valid_C_pip <span class="token operator">=</span> Pipeline<span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">&quot;std&quot;</span><span class="token punctuation">,</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">&quot;svm_valid_C&quot;</span><span class="token punctuation">,</span> svm_valid_C<span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
svm_valid_C_pip<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>data<span class="token punctuation">,</span> target<span class="token punctuation">)</span>
valid_param <span class="token operator">=</span> svm_valid_C_pip<span class="token punctuation">[</span><span class="token string">&quot;svm_valid_C&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>best_params_
cv_result <span class="token operator">=</span> svm_valid_C_pip<span class="token punctuation">[</span><span class="token string">&quot;svm_valid_C&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cv_results_
 获取超参数在不同取值的交叉验证均值与标准差
mean_score <span class="token operator">=</span> cv_result<span class="token punctuation">[</span><span class="token string">&quot;mean_test_score&quot;</span><span class="token punctuation">]</span>
std_score <span class="token operator">=</span> cv_result<span class="token punctuation">[</span><span class="token string">&quot;std_test_score&quot;</span><span class="token punctuation">]</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;valid params: </span><span class="token interpolation"><span class="token punctuation">{</span>valid_param<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>

axe <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token punctuation">)</span>
 将均值绘制为曲线
axe<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>c_valid_list<span class="token punctuation">,</span> mean_score<span class="token punctuation">,</span> linestyle <span class="token operator">=</span> <span class="token string">&quot;-&quot;</span><span class="token punctuation">,</span> marker <span class="token operator">=</span> <span class="token string">&quot;o&quot;</span><span class="token punctuation">,</span> color <span class="token operator">=</span> <span class="token string">&quot;C1&quot;</span><span class="token punctuation">)</span>
 使用 fill_between 绘制区域<span class="token punctuation">,</span> 以 <span class="token number">3</span>σ 作为波动范围
axe<span class="token punctuation">.</span>fill_between<span class="token punctuation">(</span>c_valid_list<span class="token punctuation">,</span> mean_score <span class="token operator">-</span> <span class="token number">3</span> <span class="token operator">*</span> std_score<span class="token punctuation">,</span> mean_score <span class="token operator">+</span> <span class="token number">3</span> <span class="token operator">*</span> std_score<span class="token punctuation">,</span> 
    alpha <span class="token operator">=</span> <span class="token number">0.3</span><span class="token punctuation">,</span> color <span class="token operator">=</span> <span class="token string">&quot;C2&quot;</span><span class="token punctuation">)</span>
 使用对数轴
axe<span class="token punctuation">.</span>set_xscale<span class="token punctuation">(</span><span class="token string">&quot;log&quot;</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>代码运行效果</p><figure><img src="`+d+'" alt="" tabindex="0"><figcaption></figcaption></figure><h3 id="学习曲线" tabindex="-1"><a class="header-anchor" href="#学习曲线" aria-hidden="true">#</a> 学习曲线</h3><p>对于一般的机器学习模型, 学习曲线指不同训练样本数量下, 模型对测试集与训练集的性能标签<br> 通过学习曲线可以判断模型是否存在过拟合 (模型过拟合时准确率将随训练样本增加而下降), 寻找最适合的训练样本数</p><p>一般直接使用 Sklearn 提供的学习曲线绘制函数, 首先导入学习曲线绘制类<br><code>from sklearn.model_selection import LearningCurveDisplay</code><br> 如果需要获取详细的交叉验证信息, 可以使用同模块下的函数 <code>learning_curve</code>, 在此处不介绍</p><p>通过学习曲线绘制类下的静态方法绘制学习曲线<br><code>LearningCurveDisplay.from_estimator(estimator, X, y, train_sizes = None, cv = 5, scoring = None)</code></p><ul><li><code>estimator</code> 用于绘制学习曲线的模型对象</li><li><code>X, y</code> 全部样本的特征与属性</li><li><code>train_sizes</code> 小于 1 的浮点数数组, 绘制学习曲线时, 每次训练集的样本占比</li><li><code>cv, scoring</code> 交叉验证参数, 含义同 <a href="#k-%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81">cross_val_score()</a></li></ul><p>可以参考决策树部分的示例<a href="#%E5%86%B3%E7%AD%96%E6%A0%91%E8%B0%83%E6%95%B4">决策树调整</a></p><h2 id="高级使用" tabindex="-1"><a class="header-anchor" href="#高级使用" aria-hidden="true">#</a> 高级使用</h2><h3 id="易得测试数据" tabindex="-1"><a class="header-anchor" href="#易得测试数据" aria-hidden="true">#</a> 易得测试数据</h3><p>通过模块 <code>sklearn.datasets</code> 可用于加载官方数据用于测试模型<br> 一般使用 <code>from sklearn import datasets</code> 导入该模块</p>',22),Tl={href:"https://scikit-learn.org/stable/datasets/toy_dataset.html",target:"_blank",rel:"noopener noreferrer"},Yl=a("<ul><li>此类数据的导入函数一般以 <code>load_</code> 为前缀</li><li>快速导入 <code>X, y = datasets.load_xxx(return_X_y = True)</code><ul><li>返回值 <code>X, y</code> 即对应了训练模型所需的样本特征与属性数组</li><li>直接调用将使用默认值 <code>return_X_y = False</code>, 返回单个数据集对象</li></ul></li><li>在寻找数据时, 注意网页介绍最后括号表明了数据用于何种问题类型的模型</li></ul>",1),Gl={href:"https://scikit-learn.org/stable/datasets/sample_generators.html#generated-datasets",target:"_blank",rel:"noopener noreferrer"},Pl=a("<ul><li>此类数据的导入函数一般以 <code>make_</code> 为前缀</li><li>生成分类或问题数据 (对于特定分布可参见官网的其他函数)<br><code>X, y = datasets.make_classification(n_samples = 100, n_features = 20, *, n_informative = 2, n_redundant = 2, n_repeated = 0, n_classes = 2, n_clusters_per_class = 2, random_state = None)</code><ul><li><code>n_samples, n_features</code> 随机生成的样本数与特征数</li><li><code>n_informative, n_redundant, n_repeated</code> 有效特征, 冗余特征 (有效特征线性组合), 重复特征数 (剩余的为无效的随机特征)</li><li><code>n_classes</code> 总类别数</li><li><code>n_clusters_per_class</code> 每个类别特征向量形成的团簇数</li><li><code>random_state</code> 随机种子</li><li>注意参数 <code>n_features</code> 应大于等于参数 <code>n_informative, n_redundant, n_repeated</code> 的和</li><li>该函数也可用于聚类问题, 即将 Y 用于验证聚类效果, 同时令 <code>n_informative</code> 尽可能大以形成明确聚类</li></ul></li><li>生成回归问题数据 (对于非线性回归数据, 见官网其他函数如 <code>dataset.friedman1()</code>)<br><code>X, y = datasets.make_regression(n_samples = 100, n_features = 20, *, n_informative = 2, n_targets = 1, noise = 0, random_state = None)</code><ul><li><code>n_samples, n_features</code> 随机生成的样本数与特征数</li><li><code>n_informative</code> 有效特征数</li><li><code>n_targets</code> 回归目标数</li><li><code>noise</code> 随机生成数据的噪音标准差</li><li><code>random_state</code> 随机种子</li></ul></li></ul>",1),Ul={href:"https://scikit-learn.org/stable/datasets/real_world.html",target:"_blank",rel:"noopener noreferrer"},Jl=a(`<ul><li>此类数据的导入函数一般以 <code>fetch_</code> 为前缀</li><li>快速导入 <code>X, y = datasets.fetch_xxx(*, return_X_y = False, data_home = None)</code><ul><li><code>return_X_y</code> 是否快速导入, 建议设置为 <code>True</code>, 否则将返回单个数据集对象</li><li><code>data_home</code> 下载数据的保存路径</li></ul></li></ul><h3 id="划分训练集与测试集" tabindex="-1"><a class="header-anchor" href="#划分训练集与测试集" aria-hidden="true">#</a> 划分训练集与测试集</h3><p>通过函数 <code>train_test_split</code> 可用于将数据集划分为训练集与测试集<br> 一般使用 <code>from sklearn.model_selection import train_test_split</code> 导入该函数</p><p><code>split = train_test_split(*array, test_size = None, random_state = None)</code></p><ul><li><code>*array</code> 被划分的数据, 要求传入的多组数据具有相同的最高为度, 一般即传入<a href="#%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE">加载数据</a>的 <code>ds.data</code> 与 <code>ds.target</code></li><li><code>test_size</code> 测试集大小, 一般传入浮点数, 表示测试集占全部样本的比例</li><li><code>random_state</code> 随机种子, 一般传入整数</li><li><code>split</code> 返回值, 为一个大小为 <code>2*len(array)</code> 的列表, 即将对应位置的元素均划分为了训练集与测试集两份</li></ul><p>一般使用以下代码加载与划分数据</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets

data<span class="token punctuation">,</span> target <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span>return_X_y <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>
    data<span class="token punctuation">,</span> target<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="数据流水线" tabindex="-1"><a class="header-anchor" href="#数据流水线" aria-hidden="true">#</a> 数据流水线</h3><p>通过数据流水线对象, 能够将数据转换, 模型预测等步骤集成到一个模型中, 使模型更加可读 (类似 <a href="#%E5%B8%B8%E7%94%A8%E7%BD%91%E7%BB%9C%E5%B1%82%E4%BB%8B%E7%BB%8D">nn.Sequential</a>)</p><ul><li>通过 <code>from sklearn.pipeline import Pipeline</code> 导入数据流水线类</li><li>创建数据流水线 <code>pipe = Pipeline(steps)</code>, 参数<code>step</code> 为一个列表, 列表元素为一个 <code>(name, obj)</code> 的元组 <ul><li><code>name</code> 该步模型的名称, 一般由字母数组与单个下划线组成</li><li><code>obj</code> 机器学习模型或数据预处理器, 通常为一个具有类似<a href="#scikit-learn-%E6%A8%A1%E5%9E%8B%E7%89%B9%E7%82%B9">Scikit-Learn 模型特点</a>中 <code>fit</code> 与 <code>predict</code> 或 <code>transform</code> (预处理), <code>fit_predict</code> (无监督学习) 成员函数的对象</li></ul></li><li>通过流水线对象的 <code>[]</code> 运算符, 使用模型名称或步骤均可索引流水线中的模型</li><li>流水线对象同样使用成员函数 <code>fit</code> 与 <code>predict</code> 训练与预测</li></ul><p>如果希望在<a href="#%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2">网格搜索</a>中, 访问超参数时, 可使用以下两种方法</p><ul><li>将网格搜索模型作为数据流水线中的一个模型, 用于单模型的搜索</li><li>使用 <code>&lt;模型名称&gt;__&lt;模型超参数&gt;</code> 代替原来的超参数访问 (其中模型名称为流水线中的标签)</li></ul><h3 id="数据预处理" tabindex="-1"><a class="header-anchor" href="#数据预处理" aria-hidden="true">#</a> 数据预处理</h3>`,13),jl=s("br",null,null,-1),Il={href:"https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-data",target:"_blank",rel:"noopener noreferrer"},Ol=s("ul",null,[s("li",null,[s("code",null,"StandardScaler"),n(" 特征标准化 "),s("ul",null,[s("li",null,"对于绝大部分机器学习的输入数据均需要归一化以得到更好的效果, 特别是包含正则化的模型"),s("li",null,[n("该对象将输入的样本特征 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"x")]),s("annotation",{encoding:"application/x-tex"},"x")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"x")])])]),n(" 进行标准化处理 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"y"),s("mo",null,"="),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",null,"−"),s("msub",null,[s("mi",null,"μ"),s("mi",null,"x")]),s("mo",{stretchy:"false"},")"),s("mi",{mathvariant:"normal"},"/"),s("msub",null,[s("mi",null,"s"),s("mi",null,"x")])]),s("annotation",{encoding:"application/x-tex"},"y=(x-\\mu_x)/s_x")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"μ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"x")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mord"},"/"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"s"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"x")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])])]),s("li",null,[n("通过 "),s("code",null,"from sklearn.preprocessing import StandardScaler"),n(" 导入类")]),s("li",null,[n("使用 "),s("code",null,"StandardScaler()"),n(" 创建对象")]),s("li",null,[n("类似的有 "),s("code",null,"MinMaxScaler"),n(", 可将特征根据极大极小值归一化到范围 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mn",null,"0"),s("mo",{separator:"true"},","),s("mn",null,"1"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"(0,1)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"0"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"1"),s("span",{class:"mclose"},")")])])])])])]),s("li",null,[s("code",null,"PolynomialFeatures"),n(" 添加组合特征升维 "),s("ul",null,[s("li",null,"通常用于线性回归的非线性化"),s("li",null,[n("该对象将创建新的样本特征如 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msubsup",null,[s("mi",null,"x"),s("mn",null,"1"),s("mn",null,"3")]),s("mo",{separator:"true"},","),s("msubsup",null,[s("mi",null,"x"),s("mn",null,"1"),s("mn",null,"2")]),s("msub",null,[s("mi",null,"x"),s("mn",null,"2")]),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"x"),s("mn",null,"1")]),s("msub",null,[s("mi",null,"x"),s("mn",null,"2")])]),s("annotation",{encoding:"application/x-tex"},"x_1^3,x_1^2x_2,x_1x_2")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0622em","vertical-align":"-0.2481em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-2.4519em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])]),s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"3")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2481em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-2.4519em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])]),s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2481em"}},[s("span")])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),n(" 等 (次数为 3)")]),s("li",null,[n("通过 "),s("code",null,"from sklearn.preprocessing import PolynomialFeatures"),n(" 导入类")]),s("li",null,[n("使用 "),s("code",null,"PolynomialFeatures(degree = 2)"),n(" 创建对象 "),s("ul",null,[s("li",null,[s("code",null,"degree"),n(" 组合次数, 对于线性回归该参数即决定了回归曲线的次数, 该参数不应太大否则将导致输入的特征数量急剧增加")])])])])]),s("li",null,[s("code",null,"PCA"),n(" 主成分分析降维 "),s("ul",null,[s("li",null,"通常用于图像等具有极高维度的样本训练"),s("li",null,"通过将样本特征投影到 d 个超平面上, 以投影距离作为新特征, 使样本之间的差异性尽量大"),s("li",null,[n("通过 "),s("code",null,"[0, 1]"),n(" 的可解时方差比指标确定降维的有效性 (越大越好)")]),s("li",null,[n("通过 "),s("code",null,"from sklearn.decomposition import PCA"),n(" 导入类")]),s("li",null,[n("使用 "),s("code",null,"PCA(n_components)"),n(" 创建对象 "),s("ul",null,[s("li",null,[s("code",null,"n_components"),n(" 控制超平面数量的超参数 "),s("ul",null,[s("li",null,"传入整数时表示超平面数量, 即降维后输出样本的特征数 (降维为 2 维用于数据可视化)"),s("li",null,[n("传入 "),s("code",null,"[0, 1]"),n(" 的浮点数表示降维后允许最低的可解释方差比 (一般用法, 通常要求 "),s("code",null,"0.9"),n(")")])])]),s("li",null,[n("通过成员 "),s("code",null,"explained_variance_ratio_"),n(" 可以获取各个新维度的可解释方差比")])])])])])],-1);function Ql(Wl,Zl){const t=c("ExternalLinkIcon");return l(),o("div",null,[m,s("p",null,[n("参见 "),s("a",h,[n("https://scikit-learn.org/stable/modules/linear_model.html#regression"),e(t)])]),_,v,k,g,s("p",null,[n("假设每个样本均使用固定几个特征进行描述, 则可以使用一个向量 "),s("span",y,[b,s("span",w,[s("span",x,[f,s("span",E,[s("span",B,[s("span",A,[s("span",M,[q,s("span",z,[C,s("span",S,[s("span",K,[(l(),o("svg",X,F))])])])])])])])])])]),n(" 表示一条样本")]),D,s("p",V,[s("span",R,[s("span",H,[N,s("span",T,[Y,s("span",G,[P,s("span",U,[s("span",J,[s("span",j,[s("span",I,[s("span",O,[Q,s("span",W,[Z,s("span",$,[s("span",ss,[(l(),o("svg",ns,ts))])])])])])])]),es]),s("span",ls,[s("span",os,[s("span",is,[s("span",cs,[ps,s("span",rs,[ds,s("span",us,[s("span",ms,[(l(),o("svg",hs,vs))])])])])])])]),ks,gs,ys]),bs])])])]),s("p",null,[n("其中参数 "),s("span",ws,[xs,s("span",fs,[s("span",Es,[Bs,s("span",As,[s("span",Ms,[s("span",qs,[s("span",zs,[Cs,s("span",Ss,[Ks,s("span",Xs,[s("span",Ls,[(l(),o("svg",Fs,Vs))])])])])])])])])])]),n(" 为系数向量, "),Rs,n(" 为偏置, 通过最小二乘法或梯度下降法训练模型得到以上两个参数")]),Hs,s("p",Ns,[s("span",Ts,[s("span",Ys,[Gs,s("span",Ps,[Us,s("span",Js,[js,s("span",Is,[s("span",Os,[Qs,s("span",Ws,[s("span",Zs,[s("span",$s,[s("span",sn,[s("span",nn,[s("span",an,[s("span",tn,[en,s("span",ln,[on,s("span",cn,[s("span",pn,[s("span",rn,[s("span",dn,[s("span",un,[mn,s("span",hn,[_n,s("span",vn,[s("span",kn,[(l(),o("svg",gn,bn))])])])])])])]),wn]),s("span",xn,[s("span",fn,[s("span",En,[s("span",Bn,[An,s("span",Mn,[qn,s("span",zn,[s("span",Cn,[(l(),o("svg",Sn,Xn))])])])])])])]),Ln])])]),Fn]),Dn])])])]),Vn]),Rn]),Hn,Nn,Tn]),s("span",Yn,[Gn,Pn,Un,Jn,s("span",jn,[s("span",In,[s("span",On,[s("span",Qn,[Wn,s("span",Zn,[$n,s("span",sa,[s("span",na,[(l(),o("svg",aa,ea))])])])])])])]),la])])])])]),s("ul",null,[s("li",null,[n("岭回归 "),oa,n(", 以 L2 范数为惩罚函数 "),s("span",ia,[ca,s("span",pa,[s("span",ra,[da,ua,ma,s("span",ha,[s("span",_a,[s("span",va,[s("span",ka,[ga,s("span",ya,[ba,s("span",wa,[s("span",xa,[(l(),o("svg",fa,Ba))])])])])])])]),Aa,Ma,qa,za]),s("span",Ca,[Sa,s("span",Ka,[s("span",Xa,[La,s("span",Fa,[s("span",Da,[s("span",Va,[s("span",Ra,[s("span",Ha,[s("span",Na,[s("span",Ta,[Ya,s("span",Ga,[s("span",Pa,[s("span",Ua,[s("span",Ja,[s("span",ja,[Ia,s("span",Oa,[Qa,s("span",Wa,[s("span",Za,[(l(),o("svg",$a,nt))])])])])])])])])])]),at]),tt])])])]),et]),lt])])])]),n(" 使每个系数尽可能小且均能发挥作用以避免过拟合, 称为 L2 正则化")]),s("li",null,[n("Lasso 回归 "),ot,n(", 类似岭回归, 以 L1 范数为惩罚函数 "),s("span",it,[ct,s("span",pt,[s("span",rt,[dt,ut,mt,s("span",ht,[s("span",_t,[s("span",vt,[s("span",kt,[gt,s("span",yt,[bt,s("span",wt,[s("span",xt,[(l(),o("svg",ft,Bt))])])])])])])]),At,Mt,qt,zt]),s("span",Ct,[St,s("span",Kt,[s("span",Xt,[Lt,s("span",Ft,[s("span",Dt,[s("span",Vt,[s("span",Rt,[s("span",Ht,[s("span",Nt,[s("span",Tt,[Yt,s("span",Gt,[s("span",Pt,[s("span",Ut,[s("span",Jt,[s("span",jt,[It,s("span",Ot,[Qt,s("span",Wt,[s("span",Zt,[(l(),o("svg",$t,ne))])])])])])])])])])]),ae]),te])])])]),ee]),le])])])]),n(" , 能产生稀疏的系数矩阵")]),oe]),ie,s("ul",null,[s("li",null,[n("逻辑回归 "),ce,n(", 使用 "),s("span",pe,[re,s("span",de,[ue,s("span",me,[he,_e,ve,s("span",ke,[s("span",ge,[s("span",ye,[s("span",be,[s("span",we,[xe,s("span",fe,[Ee,s("span",Be,[s("span",Ae,[(l(),o("svg",Me,ze))])])])])])])]),Ce]),s("span",Se,[s("span",Ke,[s("span",Xe,[s("span",Le,[Fe,s("span",De,[Ve,s("span",Re,[s("span",He,[(l(),o("svg",Ne,Ye))])])])])])])]),Ge,Pe,Ue]),Je])]),n(" 代替一般回归, 可用分类问题")])]),s("p",null,[n("关于其他回归模型的介绍见 "),s("a",je,[n("https://mp.weixin.qq.com/s/mr83EK24S94b_UUlecyqlA"),e(t)])]),Ie,s("p",null,[n("参见 "),s("a",Oe,[n("https://scikit-learn.org/stable/modules/svm.html#svm"),e(t)])]),Qe,s("ul",null,[s("li",null,[We,n(" 核函数, 使用字符串表示, 常用的有 "),s("ul",null,[Ze,$e,sl,s("li",null,[n("关于不同核函数的效果可参见"),s("a",nl,[n("官网例程"),e(t)])])])]),al,s("li",null,[tl,n(" 惩罚系数 "),s("ul",null,[el,s("li",null,[n("反比于正则化程度, 具体设置可参考"),s("a",ll,[n("官网介绍"),e(t)])])])]),ol,il]),cl,pl,rl,dl,ul,ml,s("p",null,[n("参见 "),s("a",hl,[n("https://scikit-learn.org/stable/modules/tree.html#decision-trees"),e(t)])]),_l,s("ul",null,[vl,s("li",null,[n("其他正则化超参数见"),s("a",kl,[n("官网介绍"),e(t)]),n(", 实际使用时, 一般先不加约束的训练, 再根据决策树形状调整超参数")])]),gl,s("p",null,[n("参见 "),s("a",yl,[n("https://scikit-learn.org/stable/modules/ensemble.html"),e(t)])]),bl,s("p",null,[n("参见 "),s("a",wl,[n("https://scikit-learn.org/stable/modules/ensemble.html#adaboost"),e(t)])]),xl,s("p",null,[n("参见 "),s("a",fl,[n("https://scikit-learn.org/stable/modules/clustering.html#k-means"),e(t)])]),El,s("ul",null,[Bl,Al,Ml,ql,zl,s("li",null,[n("更多可参考专门的标签传播模型 "),s("a",Cl,[n("https://scikit-learn.org/stable/modules/semi_supervised.html"),e(t)])])]),Sl,s("p",null,[n("参考 "),s("a",Kl,[n("https://scikit-learn.org/stable/modules/clustering.html#overview-of-clustering-methods"),e(t)])]),Xl,s("ul",null,[Ll,s("li",null,[n("对于更多的评价指标可参见"),s("a",Fl,[n("官方文档"),e(t)])]),Dl]),Vl,Rl,Hl,Nl,s("p",null,[s("a",Tl,[n("简单数据测试"),e(t)])]),Yl,s("p",null,[s("a",Gl,[n("随机生成数据"),e(t)])]),Pl,s("p",null,[s("a",Ul,[n("真实下载数据"),e(t)])]),Jl,s("p",null,[n("以下为常用的数据预处理对象"),jl,n(" 更多参见 "),s("a",Il,[n("https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-data"),e(t)])]),Ol])}const no=i(u,[["render",Ql],["__file","scikit-learn.html.vue"]]);export{no as default};
